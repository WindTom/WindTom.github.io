---
layout: post
title: "Hadoop平台学习"
description: ""
category: 数据挖掘
tags: [hadoop,data mining]
---
* content
{:toc}

## Hadoop和Spark的区别

Hadoop和Spark都是大数据框架，但是各自存在不同的目的。Hadoop更多的是一个分布式数据基础设施，它将巨大的数据分派在计算机集群的多个节点上。

同时，Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。Spark则是专门用来对分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。

Hadoop的数据存储功能叫做HDFS，它还提供了一个叫做MapReduce的数据处理功能，这个数据处理功能完全可以用Spark代替。

反之，Spark也可以不用在Hadoop上，而是用在其他的分布式系统上面。但Spark默认来说还是被用在Hadoop上面的。另外，spark的数据处理速度秒杀MapReduce

## HDFS(Hadoop Distributed File System)

传统的文件系统是单机的，不能横跨不同的机器。HDFS也是一个文件系统，但它的存储是分布在不同机器上的。从用户角度看，用户看到的只是一个平常的文件系统，如/hdfs/tmp/file1这个路径下的文件可能被存储在多个机器上，而用户根本感觉不到。

## 平台选择

MapReduce是第一代数据处理引擎，Tez、Spark是第二代。

对于**中低速数据处理**，可以在`底层HDFS，上面跑MapReduce/Tez/Spark，再上面跑Hive、Pig`；或者`HDFS上直接跑Impala、Drill、Presto`

对于**高速数据处理**,出现了新的计算模型——Streaming（流）计算。`Storm是最流行的流计算平台`。流计算基本无延迟，但缺点是不灵活，想要统计的东西必须事先知道，毕竟数据流过就没了，无法补算。

还有一个有些独立的模块是**KV Store**，比如Cassandra、HBase、MongoDB以及很多其他的。KV Store的主要作用是能够快速获取与键值（Key）绑定的数据。比如，从几个P的数据中查找一个身份证号，也许只要零点几秒。缺点是基本无法处理复杂的计算，大多没法Join，没有强一致性保证，但速度极快。

此外，还有一些**特制的系统或者组件**，如Mahout是分布式机器学习库，Protobuf是数据交换的编码和库，ZooKeeper是高一致性的分布存取系统系统，等等。

这些乱七八糟的工具都在同一个集群上运转，就需要有一个管理员保证工作有序进行，所以另一个重要的组件就是**调度系统**。现在`最流行的是Yarn`。




## 参考资料
1. [一文看懂大数据的技术生态圈](http://www.36dsj.com/archives/23504)

2. [2分钟读懂Hadoop和Spark的异同](https://www.baidu.com/link?url=9SF6A_NT8DmO1sGBDwCIRxpPxUs6tAh9HHuyKB49_cXvgPcfSwSSjjwdM4SBL0LB1Sw48WkWRXGVYc3hIzK9rRLEJGRMQv9NrrJyMQqQrd3&wd=&eqid=b8a9880c0001199f0000000557cccbcb)

<div align="center"><table style="text-align: center; width: 100%;" border="1" cellpadding="1" cellspacing="1">

<tr>
<td><img src=""></td>
<td><img src=""></td>
</tr>

<tr>
<td><p><small><b> </b></small></p></td>
<td><p><small><b> </b></small></p></td>
</tr>

<br><br></table></div>